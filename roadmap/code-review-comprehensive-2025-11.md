# Comprehensive Code Review: LLM API Server

**Review Date:** 2025-11-27
**Reviewer:** Claude (Opus 4.5)
**Version Reviewed:** 0.5.1
**Commit:** 96f531d
**Overall Grade:** B+ (Good quality with some notable issues)

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Architecture Overview](#architecture-overview)
3. [Module-by-Module Analysis](#module-by-module-analysis)
4. [Security Analysis](#security-analysis)
5. [Performance Analysis](#performance-analysis)
6. [Code Quality Assessment](#code-quality-assessment)
7. [Test Coverage Analysis](#test-coverage-analysis)
8. [Recommendations](#recommendations)
9. [Appendix: File-by-File Notes](#appendix-file-by-file-notes)

---

## Executive Summary

### What This Project Is

LLM API Server is a reusable Flask framework for building OpenAI-compatible API servers that proxy to local LLM backends (Ollama and LM Studio). It provides:

- OpenAI-compatible REST API (`/v1/chat/completions`, `/v1/models`)
- LangChain tool calling with automatic execution loop
- RAG (Retrieval-Augmented Generation) document search module
- Evaluation framework for testing LLM responses
- Optional Open Web UI integration

### Strengths

| Area | Assessment |
|------|------------|
| **Architecture** | Clean separation of concerns, extensible design |
| **Documentation** | Excellent CLAUDE.md, good docstrings |
| **Error Handling** | Comprehensive with retry logic and user-friendly messages |
| **RAG Module** | Sophisticated hybrid search with parent-child chunking |
| **Configurability** | Extensive options via environment variables |

### Weaknesses

| Area | Assessment |
|------|------------|
| **Security** | Calculator accepts non-numeric types, FAISS deserialization risk |
| **Thread Safety** | Race condition in system prompt caching |
| **Test Coverage** | RAG module completely untested |
| **Type Safety** | Inconsistent type hints across modules |

### Risk Summary

| Priority | Count | Description |
|----------|-------|-------------|
| üî¥ Critical | 3 | Security vulnerabilities requiring immediate attention |
| üü° Medium | 8 | Bugs and design issues affecting reliability |
| üîµ Minor | 12 | Code quality and maintainability improvements |

---

## Architecture Overview

### Package Structure

```
llm-api-server/
‚îú‚îÄ‚îÄ llm_api_server/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          # Public API exports
‚îÇ   ‚îú‚îÄ‚îÄ server.py            # Core LLMServer Flask application (711 lines)
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # ServerConfig base class (120 lines)
‚îÇ   ‚îú‚îÄ‚îÄ backends.py          # Ollama/LM Studio communication (195 lines)
‚îÇ   ‚îú‚îÄ‚îÄ builtin_tools.py     # Date, calculator, search tools (258 lines)
‚îÇ   ‚îú‚îÄ‚îÄ web_search_tool.py   # Ollama web search implementation
‚îÇ   ‚îú‚îÄ‚îÄ webui.py             # Open Web UI subprocess management
‚îÇ   ‚îú‚îÄ‚îÄ eval/                # Evaluation framework
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluator.py     # Test execution engine (173 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_case.py     # TestCase/TestResult dataclasses
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validators.py    # Response validation (53 lines)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reporters.py     # HTML/JSON/Console output
‚îÇ   ‚îî‚îÄ‚îÄ rag/                 # RAG document search
‚îÇ       ‚îú‚îÄ‚îÄ config.py        # RAGConfig dataclass (99 lines)
‚îÇ       ‚îú‚îÄ‚îÄ crawler.py       # Web crawler (464 lines)
‚îÇ       ‚îú‚îÄ‚îÄ chunker.py       # Semantic HTML chunking (832 lines)
‚îÇ       ‚îî‚îÄ‚îÄ indexer.py       # DocSearchIndex class (985 lines)
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ conftest.py          # Pytest fixtures
    ‚îú‚îÄ‚îÄ test_server.py       # Server unit tests
    ‚îú‚îÄ‚îÄ test_backends.py     # Backend tests
    ‚îú‚îÄ‚îÄ test_config.py       # Config tests
    ‚îî‚îÄ‚îÄ test_web_search.py   # Web search tests
```

### Data Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Client Request                            ‚îÇ
‚îÇ                    POST /v1/chat/completions                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         LLMServer                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Rate Limit  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Validation   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ System Prompt    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ (optional)  ‚îÇ    ‚îÇ & Parsing    ‚îÇ    ‚îÇ Loading (cached) ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                   ‚îÇ              ‚îÇ
‚îÇ                                                   ‚ñº              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                    Tool Calling Loop                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Backend ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Tool     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Execute Tools   ‚îÇ    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Call    ‚îÇ    ‚îÇ Detection‚îÇ    ‚îÇ (up to 5 iter)  ‚îÇ    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ       ‚ñ≤                                   ‚îÇ              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Backend (Ollama/LM Studio)                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Retry Logic: 3 attempts, exponential backoff (1s, 2s, 4s) ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### RAG Pipeline

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      RAG Indexing Pipeline                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                   ‚îÇ
‚îÇ  Phase 1: URL Discovery                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ Sitemap.xml ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Recursive   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Manual URLs ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ (preferred) ‚îÇ    ‚îÇ Crawl       ‚îÇ    ‚îÇ (additive)  ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  Phase 2: Content Fetching                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ Parallel    ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Readability ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Cache to    ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ HTTP (5)    ‚îÇ    ‚îÇ Extraction  ‚îÇ    ‚îÇ Disk        ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  Phase 3: Chunking                                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Semantic HTML Chunking (heading hierarchy)               ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îÇ Parent Chunks   ‚îÇ    ‚îÇ Child Chunks                ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îÇ (~900 tokens)   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ (~350 tokens, searchable)   ‚îÇ  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îÇ  Phase 4: Index Building                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ HuggingFace ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ FAISS       ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ BM25        ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ Embeddings  ‚îÇ    ‚îÇ Vector Store‚îÇ    ‚îÇ Keyword     ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      RAG Search Pipeline                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Query       ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Ensemble Retriever  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Cross-Encoder‚îÇ  ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ    ‚îÇ (BM25 + Semantic)   ‚îÇ    ‚îÇ Re-ranking   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ    ‚îÇ Reciprocal Rank     ‚îÇ    ‚îÇ (MS MARCO)   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ    ‚îÇ Fusion (RRF)        ‚îÇ    ‚îÇ              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                       ‚îÇ          ‚îÇ
‚îÇ                                                       ‚ñº          ‚îÇ
‚îÇ                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ                              ‚îÇ Results with Parent Context     ‚îÇ ‚îÇ
‚îÇ                              ‚îÇ (child_to_parent mapping)       ‚îÇ ‚îÇ
‚îÇ                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Module-by-Module Analysis

### 1. Core Server (`llm_api_server/server.py`)

**Lines:** 711
**Complexity:** Medium-High
**Test Coverage:** Partial

#### Responsibilities
- Flask application setup with CORS
- Route handling (`/health`, `/v1/models`, `/v1/chat/completions`)
- Tool calling loop (max 5 iterations)
- Streaming and non-streaming response handling
- System prompt loading with caching
- Rate limiting (optional)
- Debug logging with rotation

#### Code Quality

**Positive:**
- Clean class structure with clear method separation
- Good error messages with troubleshooting hints
- Proper timeout handling with user-friendly responses

**Issues Found:**

| Line | Issue | Severity |
|------|-------|----------|
| 137-148 | Race condition in system prompt caching (mtime check not atomic with read) | üü° Medium |
| 292-398 | `full_messages` list grows unbounded in tool loop | üü° Medium |
| 248-251 | Tool arguments passed without validation | üü° Medium |
| 63 | Flask app name uses `name.lower()` which could conflict | üîµ Minor |

#### Key Methods

```python
# server.py:130-151 - System prompt loading with caching
def get_system_prompt(self) -> str:
    """Load system prompt from markdown file with smart caching."""
    prompt_path = Path(self.config.SYSTEM_PROMPT_PATH)
    if not prompt_path.exists():
        return self.default_system_prompt
    try:
        current_mtime = prompt_path.stat().st_mtime
        # ISSUE: Race condition - file can change between stat() and read_text()
        if self._system_prompt_cache is not None and self._system_prompt_mtime == current_mtime:
            return self._system_prompt_cache
        self._system_prompt_cache = prompt_path.read_text(encoding="utf-8")
        self._system_prompt_mtime = current_mtime
        return self._system_prompt_cache
    except Exception as e:
        print(f"Error reading system prompt: {e}")
        return self.default_system_prompt
```

```python
# server.py:281-418 - Main chat completion processing
def process_chat_completion(self, messages: list[dict], temperature: float,
                           max_iterations: int | None = None) -> dict:
    """Process chat completion with tool calling loop (non-streaming)."""
    # Handles:
    # - System prompt injection
    # - Backend calls with timeout/connection error handling
    # - Tool execution loop (up to max_iterations)
    # - Response formatting (OpenAI-compatible)
```

---

### 2. Configuration (`llm_api_server/config.py`)

**Lines:** 120
**Complexity:** Low
**Test Coverage:** Yes

#### Responsibilities
- Define all configuration options with defaults
- Load from environment variables with optional prefix
- Support subclassing for project-specific config

#### Configuration Options

| Category | Options |
|----------|---------|
| **Backend** | `BACKEND_TYPE`, `BACKEND_MODEL`, `LMSTUDIO_ENDPOINT`, `OLLAMA_ENDPOINT` |
| **Server** | `DEFAULT_HOST`, `DEFAULT_PORT`, `DEFAULT_TEMPERATURE`, `THREADED` |
| **Timeouts** | `BACKEND_CONNECT_TIMEOUT` (10s), `BACKEND_READ_TIMEOUT` (300s) |
| **Retry** | `BACKEND_RETRY_ATTEMPTS` (3), `BACKEND_RETRY_INITIAL_DELAY` (1.0s) |
| **Rate Limiting** | `RATE_LIMIT_ENABLED`, `RATE_LIMIT_DEFAULT`, `RATE_LIMIT_STORAGE_URI` |
| **Debug** | `DEBUG_TOOLS`, `DEBUG_TOOLS_LOG_FILE`, `DEBUG_LOG_MAX_BYTES` |
| **Health** | `HEALTH_CHECK_ON_STARTUP`, `HEALTH_CHECK_TIMEOUT` |
| **Tools** | `MAX_TOOL_ITERATIONS` (5) |
| **WebUI** | `WEBUI_PORT`, `ENABLE_WEBUI` |

#### Issues Found

| Line | Issue | Severity |
|------|-------|----------|
| 100 | Inconsistent boolean parsing logic between `THREADED` and `DEBUG_TOOLS` | üü° Medium |
| 91 | Environment variable name mismatch: `BACKEND` vs `BACKEND_TYPE` | üîµ Minor |

```python
# config.py:100-102 - Inconsistent boolean parsing
config.THREADED = get_env("THREADED", "").lower() not in ("false", "0", "no")  # Default True
# vs
config.DEBUG_TOOLS = get_env("DEBUG_TOOLS", "").lower() in ("true", "1", "yes")  # Default False
```

---

### 3. Backend Communication (`llm_api_server/backends.py`)

**Lines:** 195
**Complexity:** Medium
**Test Coverage:** Partial

#### Responsibilities
- Call Ollama API (`/api/chat`)
- Call LM Studio API (`/chat/completions`)
- Convert tools to backend-specific formats
- Retry on connection errors with exponential backoff
- Health checks for both backends

#### Key Functions

| Function | Purpose |
|----------|---------|
| `call_ollama()` | Send chat request to Ollama with tool support |
| `call_lmstudio()` | Send chat request to LM Studio (OpenAI format) |
| `check_ollama_health()` | Verify Ollama is running and model is loaded |
| `check_lmstudio_health()` | Verify LM Studio is running with models |
| `get_tool_schema()` | Extract schema from LangChain tools (Pydantic v1/v2 compatible) |
| `_retry_on_connection_error()` | Retry wrapper with exponential backoff |

#### Retry Logic

```python
# backends.py:19-56 - Exponential backoff retry
def _retry_on_connection_error(func: Callable, config, *args, **kwargs):
    """Retry a function on connection errors with exponential backoff.

    - Only retries on ConnectionError (not HTTP errors or timeouts)
    - Delays: 1s, 2s, 4s (exponential)
    - Max attempts: configurable (default 3)
    """
    max_attempts = config.BACKEND_RETRY_ATTEMPTS
    initial_delay = config.BACKEND_RETRY_INITIAL_DELAY

    for attempt in range(max_attempts):
        try:
            return func(*args, **kwargs)
        except requests.ConnectionError as e:
            if attempt < max_attempts - 1:
                delay = initial_delay * (2**attempt)
                time.sleep(delay)
        except (requests.HTTPError, requests.Timeout) as e:
            raise e  # Don't retry these
    raise last_exception
```

#### Issues Found

| Line | Issue | Severity |
|------|-------|----------|
| 59, 93 | `tools: list` parameter not typed as `list[BaseTool]` | üîµ Minor |
| 86-88 | Response not validated before returning | üîµ Minor |

---

### 4. Built-in Tools (`llm_api_server/builtin_tools.py`)

**Lines:** 258
**Complexity:** Medium
**Test Coverage:** None

#### Available Tools

| Tool | Description | Always Available |
|------|-------------|------------------|
| `get_current_datetime()` | Returns formatted local date/time | Yes |
| `calculate(expression)` | Safe math expression evaluator | Yes |
| `create_web_search_tool(config)` | Ollama API web search factory | No (requires API key) |
| `create_doc_search_tool(index)` | RAG document search factory | No (requires RAG index) |

#### Calculator Implementation

```python
# builtin_tools.py:43-109 - Safe expression evaluation using AST
@tool
def calculate(expression: str) -> str:
    """Safely evaluate a mathematical expression."""
    ALLOWED_OPERATORS = {
        ast.Add: operator.add,
        ast.Sub: operator.sub,
        ast.Mult: operator.mul,
        ast.Div: operator.truediv,
        ast.FloorDiv: operator.floordiv,
        ast.Mod: operator.mod,
        ast.Pow: operator.pow,
        ast.USub: operator.neg,
    }

    def eval_node(node):
        if isinstance(node, ast.Constant):  # ISSUE: Accepts any constant, not just numbers
            return node.value
        elif isinstance(node, ast.BinOp):
            # ... binary operations
        elif isinstance(node, ast.UnaryOp):
            # ... unary operations
        else:
            raise ValueError(f"Unsupported expression type")
```

#### Issues Found

| Line | Issue | Severity |
|------|-------|----------|
| 75 | `ast.Constant` check accepts non-numeric types (strings, None, etc.) | üî¥ Critical |
| 102-108 | Error messages may leak expression content | üü° Medium |
| 227-228 | Parent context truncated to 500 chars unconditionally | üü° Medium |

---

### 5. RAG Crawler (`llm_api_server/rag/crawler.py`)

**Lines:** 464
**Complexity:** Medium
**Test Coverage:** None

#### Crawling Modes

| Mode | Trigger | Description |
|------|---------|-------------|
| **Sitemap** | `sitemap.xml` found | Parse sitemap XML, follow sitemap indexes |
| **Recursive** | No sitemap | Follow links from base URL up to max depth |
| **Manual** | `manual_urls` provided | Index specific URLs only |

#### Features

- Robots.txt respect (with subdomain fallback)
- URL include/exclude patterns (regex)
- Rate limiting (configurable delay)
- Parallel fetching (configurable workers)
- Content type filtering (HTML only)
- URL normalization (remove query params, anchors, trailing slashes)

#### Issues Found

| Line | Issue | Severity |
|------|-------|----------|
| 391-419 | No redirect domain validation - could crawl external sites | üü° Medium |
| 346-350 | No backoff for HTTP 429/5xx errors | üü° Medium |
| 382 | Tuple comparison `(href, depth + 1) not in to_visit` is O(n) | üîµ Minor |

```python
# crawler.py:391-419 - Fetch without redirect validation
def fetch_page(self, url: str) -> tuple[str, str] | None:
    """Fetch a single page and return (url, html_content)."""
    # ...
    response = requests.get(url, headers={"User-Agent": self.user_agent},
                           timeout=self.request_timeout)
    # ISSUE: response.url may be different domain after redirect
    response.raise_for_status()
    return (url, response.text)  # Returns original URL, not final URL
```

---

### 6. RAG Chunker (`llm_api_server/rag/chunker.py`)

**Lines:** 832
**Complexity:** High
**Test Coverage:** None

#### Chunking Strategy

```
HTML Document
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Heading Hierarchy Detection            ‚îÇ
‚îÇ  (h1 > h2 > h3 > h4 > h5 > h6)         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Section Extraction                      ‚îÇ
‚îÇ  - Content blocks (p, div, ul, ol, etc) ‚îÇ
‚îÇ  - Code blocks (pre/code, kept atomic)  ‚îÇ
‚îÇ  - Tables (kept atomic)                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Parent Chunk Creation                   ‚îÇ
‚îÇ  - Target: 300-900 tokens               ‚îÇ
‚îÇ  - Split on paragraph boundaries        ‚îÇ
‚îÇ  - Oversized: split on sentences        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ
    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Child Chunk Creation                    ‚îÇ
‚îÇ  - Target: 150-350 tokens               ‚îÇ
‚îÇ  - Small content: merge with adjacent   ‚îÇ
‚îÇ  - Large content: split on sentences    ‚îÇ
‚îÇ  - Code/tables: keep atomic             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Token Counting

Uses `tiktoken` with `cl100k_base` encoding (GPT-4/GPT-3.5-turbo tokenizer).

```python
# chunker.py:68-79
tokenizer = tiktoken.get_encoding("cl100k_base")

def count_tokens(text: str) -> int:
    if not text:
        return 0
    return len(tokenizer.encode(text, disallowed_special=()))
```

#### Chunk Metadata

```python
# chunker.py:54-66
@dataclass
class ChunkMetadata:
    heading_path: list[str]           # ["Installation", "Docker", "Configuration"]
    heading_path_joined: str          # "Installation > Docker > Configuration"
    section_id: str                   # URL-safe section identifier
    url: str                          # Source URL (canonicalized)
    doc_type: str                     # "docs", "api", "tutorial", "cli", etc.
    version: str | None               # Extracted version number
    code_identifiers: str             # Extracted function names, flags, env vars
    is_parent: bool                   # True for parent chunks
    parent_id: str | None             # Reference to parent chunk
```

#### Issues Found

| Line | Issue | Severity |
|------|-------|----------|
| 50 | `MIN_CONTENT_LENGTH = 20` magic number undocumented | üîµ Minor |
| 89 | `absolute_max_tokens = 1200` not configurable | üîµ Minor |
| 619 | `child_min_tokens // 2` threshold for merged content may create low-quality chunks | üü° Medium |

---

### 7. RAG Indexer (`llm_api_server/rag/indexer.py`)

**Lines:** 985
**Complexity:** High
**Test Coverage:** None

#### Index Components

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Embeddings** | HuggingFace `all-MiniLM-L6-v2` | Generate semantic vectors |
| **Vector Store** | FAISS (CPU) | Semantic similarity search |
| **Keyword Search** | BM25Retriever | Lexical matching |
| **Hybrid Fusion** | EnsembleRetriever (RRF) | Combine BM25 + semantic |
| **Re-ranking** | CrossEncoder (MS MARCO) | Final result ordering |

#### Hybrid Search Algorithm

Uses **Reciprocal Rank Fusion (RRF)**, not weighted score averaging:

```
RRF_score(doc) = Œ£ (weight_i / (rank_i + k))

where:
- weight_i = retriever weight (default: BM25=0.3, semantic=0.7)
- rank_i = document rank from retriever i
- k = constant (typically 60)
```

```python
# indexer.py:740-753 - Ensemble retriever setup
self.ensemble_retriever = EnsembleRetriever(
    retrievers=[
        self.bm25_retriever,
        self.vectorstore.as_retriever(
            search_kwargs={"k": self.config.search_top_k * self.config.retriever_candidate_multiplier}
        ),
    ],
    weights=[self.config.hybrid_bm25_weight, self.config.hybrid_semantic_weight],
)
```

#### Caching Strategy

| Cache File | Contents |
|------------|----------|
| `metadata.json` | Version, last update, chunk count, embedding model |
| `chunks.json` | All child chunks (page_content + metadata) |
| `parent_chunks.json` | Parent chunks for context |
| `crawl_state.json` | Discovered URLs, indexed URLs, failed URLs |
| `pages/*.json` | Raw HTML content per URL |
| `index/faiss_index` | FAISS vector index |

#### Issues Found

| Line | Issue | Severity |
|------|-------|----------|
| 357-377 | `load_index()` doesn't rebuild `child_to_parent` mapping | üî¥ Critical |
| 47 | `INDEX_VERSION` not bumped after chunker rewrite | üî¥ Critical |
| 793-794 | FAISS `allow_dangerous_deserialization=True` without integrity check | üî¥ Critical |
| 481-482 | Potential division by zero if `pages` is empty | üü° Medium |
| 36-40 | Global logger/env modification at import time | üü° Medium |

```python
# indexer.py:357-377 - Missing child_to_parent rebuild
def load_index(self):
    """Load index from cache."""
    self.chunks = self._load_chunks() or []
    self.parent_chunks = self._load_parent_chunks() or {}
    # ISSUE: child_to_parent mapping is NOT rebuilt here
    # Search results will lack parent context after restart

    if not self.chunks:
        return

    self._initialize_components()
    self._build_retrievers()
```

---

### 8. Evaluation Framework (`llm_api_server/eval/`)

**Lines:** ~400 total
**Complexity:** Low
**Test Coverage:** Partial

#### Components

| File | Purpose |
|------|---------|
| `evaluator.py` | Send questions to API, run test suites |
| `test_case.py` | TestCase and TestResult dataclasses |
| `validators.py` | Response validation logic |
| `reporters.py` | HTML, JSON, Console output formatters |

#### TestCase Schema

```python
@dataclass
class TestCase:
    question: str                           # Query to send
    description: str = ""                   # Test description
    expected_keywords: list[str] = []       # Must appear (case-insensitive)
    unexpected_keywords: list[str] = []     # Must not appear
    min_response_length: int = 1            # Minimum chars
    max_response_length: int | None = None  # Maximum chars (optional)
    expected_pattern: str | None = None     # Regex pattern (optional)
    custom_validator: Callable | None = None # Custom validation function
    timeout: int = 120                      # Request timeout
```

#### Issues Found

| Line | Issue | Severity |
|------|-------|----------|
| `evaluator.py:73` | `response.text` in error could be very large | üîµ Minor |
| `validators.py:4` | `test_case` parameter not typed | üîµ Minor |

---

## Security Analysis

### üî¥ Critical Security Issues

#### 1. Calculator Accepts Non-Numeric Constants

**File:** `builtin_tools.py:75`

```python
def eval_node(node):
    if isinstance(node, ast.Constant):
        return node.value  # Accepts strings, None, booleans, etc.
```

**Risk:** While not directly exploitable for code execution, this violates the principle of least privilege and could cause unexpected behavior.

**Recommendation:**
```python
if isinstance(node, ast.Constant):
    if not isinstance(node.value, (int, float, complex)):
        raise ValueError(f"Only numeric constants allowed, got {type(node.value).__name__}")
    return node.value
```

#### 2. FAISS Deserialization Without Integrity Check

**File:** `indexer.py:793-794`

```python
self.vectorstore = FAISS.load_local(
    faiss_path, self.embeddings,
    allow_dangerous_deserialization=True  # Pickle-based, can execute arbitrary code
)
```

**Risk:** If an attacker can modify files in the cache directory, they could inject malicious pickle payloads that execute on load.

**Recommendation:**
1. Add SHA256 checksum verification for index files
2. Or migrate to a safer serialization format (e.g., save embeddings as numpy arrays separately)

#### 3. Missing Parent Context After Cache Load

**File:** `indexer.py:357-377`

**Risk:** After server restart, RAG search results lose parent context, degrading answer quality silently.

**Recommendation:** Rebuild `child_to_parent` mapping in `load_index()`:
```python
def load_index(self):
    self.chunks = self._load_chunks() or []
    self.parent_chunks = self._load_parent_chunks() or {}

    # Rebuild child_to_parent mapping
    self.child_to_parent = {}
    for chunk in self.chunks:
        chunk_id = chunk.metadata.get("chunk_id")
        parent_id = chunk.metadata.get("parent_id")
        if chunk_id and parent_id:
            self.child_to_parent[chunk_id] = parent_id
```

### üü° Medium Security Issues

#### 4. Tool Arguments Not Validated

**File:** `server.py:247-253`

Tool arguments from LLM responses are passed directly to tool functions. If tools have injection vulnerabilities, malicious prompts could exploit them.

**Recommendation:** Tools should validate their inputs defensively. Consider adding a validation hook before tool execution.

#### 5. Crawler Follows Redirects to External Domains

**File:** `crawler.py:391-419`

`requests.get()` follows redirects by default. A malicious redirect could cause the crawler to index content from unauthorized domains.

**Recommendation:**
```python
response = requests.get(url, ...)
final_url = response.url
if not final_url.startswith(self.base_url):
    logger.warning(f"[CRAWLER] Redirect to external domain: {final_url}")
    return None
```

---

## Performance Analysis

### Potential Bottlenecks

| Area | Issue | Impact |
|------|-------|--------|
| **RAG Embedding** | Sequential embedding generation | Slow initial indexing |
| **Tool Loop** | Unbounded message accumulation | Memory growth |
| **Backend Calls** | No connection pooling | Connection overhead |
| **System Prompt** | File I/O on every request (with caching) | Minor latency |

### Memory Usage

| Component | Memory Profile |
|-----------|----------------|
| **FAISS Index** | ~4 bytes per dimension √ó vectors (e.g., 384-dim √ó 10K docs = ~15MB) |
| **BM25 Index** | Vocabulary + document vectors |
| **Chunks List** | All document text in memory |
| **Parent Chunks** | Duplicate content for context |

### Recommendations

1. **Use connection pooling:**
```python
# backends.py - Add session reuse
self._session = requests.Session()
```

2. **Implement token budget for tool loop:**
```python
# Truncate tool results if too long
MAX_TOOL_RESULT_TOKENS = 2000
if count_tokens(tool_result) > MAX_TOOL_RESULT_TOKENS:
    tool_result = truncate_to_tokens(tool_result, MAX_TOOL_RESULT_TOKENS)
```

3. **Async RAG crawling:**
```python
# Consider aiohttp for parallel fetching
async with aiohttp.ClientSession() as session:
    tasks = [fetch_page(session, url) for url in urls]
    results = await asyncio.gather(*tasks)
```

---

## Code Quality Assessment

### Style Compliance

- **Line length:** 120 chars (configured in pyproject.toml)
- **Formatter:** Black
- **Linter:** Ruff
- **Type hints:** Partial coverage

### Type Hint Coverage

| Module | Coverage | Notes |
|--------|----------|-------|
| `server.py` | Good | Most methods typed |
| `config.py` | Good | Class attributes typed |
| `backends.py` | Partial | `tools` parameter untyped |
| `builtin_tools.py` | Good | Function signatures typed |
| `rag/indexer.py` | Good | Most methods typed |
| `rag/chunker.py` | Partial | Internal functions less typed |
| `rag/crawler.py` | Good | Methods typed |
| `eval/*.py` | Partial | Some parameters untyped |

### Docstring Coverage

| Module | Coverage | Quality |
|--------|----------|---------|
| `server.py` | Good | Comprehensive class/method docs |
| `config.py` | Excellent | All options documented |
| `backends.py` | Good | Clear function docs |
| `builtin_tools.py` | Good | Tool descriptions clear |
| `rag/*.py` | Good | Algorithm explanations present |
| `eval/*.py` | Good | Usage examples in some |

### Magic Numbers

| File | Line | Value | Should Be |
|------|------|-------|-----------|
| `chunker.py` | 50 | `20` | `MIN_CONTENT_LENGTH` constant |
| `chunker.py` | 89 | `1200` | Config parameter |
| `chunker.py` | 619 | `// 2` | Named constant with rationale |
| `evaluator.py` | 38 | `5` | Config parameter |
| `indexer.py` | 468 | `5` | Already configurable ‚úì |

---

## Test Coverage Analysis

### Current Test Files

| File | Tests | Coverage Area |
|------|-------|---------------|
| `test_server.py` | 11 | Server init, tool execution, routes |
| `test_backends.py` | ~5 | Backend calls, health checks |
| `test_config.py` | ~5 | Config loading, env vars |
| `test_web_search.py` | ~3 | Web search tool |
| `test_html_report.py` | ~3 | HTML report generation |

### Coverage Gaps

| Module | Status | Priority |
|--------|--------|----------|
| `rag/chunker.py` | ‚ùå No tests | High |
| `rag/indexer.py` | ‚ùå No tests | High |
| `rag/crawler.py` | ‚ùå No tests | High |
| `builtin_tools.py` (calculator) | ‚ùå No tests | Medium |
| `builtin_tools.py` (doc search) | ‚ùå No tests | Medium |
| Streaming responses | ‚ùå No tests | Medium |
| Tool calling loop | ‚ùå No tests | Medium |

### Recommended Test Additions

```python
# tests/test_rag_chunker.py
class TestSemanticChunker:
    def test_heading_hierarchy_extraction(self):
        """Test that heading levels are properly tracked."""

    def test_code_block_atomic_handling(self):
        """Test that code blocks are never split."""

    def test_small_content_merging(self):
        """Test that small paragraphs are merged."""

    def test_oversized_content_splitting(self):
        """Test that large content is split on sentences."""

    def test_parent_child_relationship(self):
        """Test that children reference correct parents."""

# tests/test_rag_indexer.py
class TestDocSearchIndex:
    def test_cache_save_and_load(self):
        """Test that index survives restart."""

    def test_child_to_parent_mapping_after_load(self):
        """Test that parent context is available after cache load."""

    def test_incremental_update(self):
        """Test adding new documents to existing index."""

    def test_hybrid_search_results(self):
        """Test that both BM25 and semantic contribute."""

# tests/test_calculator.py
class TestCalculator:
    def test_basic_arithmetic(self):
        assert calculate("2 + 3") == "5"

    def test_rejects_strings(self):
        result = calculate("'hello'")
        assert "error" in result.lower()

    def test_division_by_zero(self):
        result = calculate("1 / 0")
        assert "zero" in result.lower()
```

---

## Recommendations

### Immediate Actions (Critical)

1. **Fix calculator type validation** (`builtin_tools.py:75`)
   - Reject non-numeric constants
   - Effort: 15 minutes

2. **Rebuild child_to_parent in load_index** (`indexer.py:357-377`)
   - Add mapping reconstruction from chunk metadata
   - Effort: 30 minutes

3. **Bump INDEX_VERSION** (`indexer.py:47`)
   - Change to `"1.1.0-chunker-rewrite"` or similar
   - Effort: 5 minutes

### Short-term Improvements (1-2 weeks)

4. **Add FAISS integrity verification**
   - Compute and verify SHA256 checksums
   - Effort: 2 hours

5. **Fix system prompt race condition** (`server.py:137-148`)
   - Use threading lock or read-then-verify pattern
   - Effort: 1 hour

6. **Standardize boolean env parsing** (`config.py`)
   - Create helper function
   - Effort: 30 minutes

7. **Add RAG module tests**
   - Start with chunker (most complex)
   - Effort: 1-2 days

### Medium-term Improvements (1 month)

8. **Implement connection pooling** for backends
   - Use `requests.Session`
   - Effort: 2 hours

9. **Add token budget for tool loop**
   - Prevent unbounded memory growth
   - Effort: 4 hours

10. **Document hybrid search semantics**
    - Explain RRF vs weighted average
    - Effort: 2 hours

11. **Add crawler redirect validation**
    - Check final URL against base_url
    - Effort: 1 hour

### Long-term Improvements (Quarterly)

12. **Implement async RAG crawling**
    - Use aiohttp for better performance
    - Effort: 1-2 weeks

13. **Add proper dependency injection**
    - Improve testability
    - Effort: 1 week

14. **Consider alternative serialization**
    - Replace pickle-based FAISS storage
    - Effort: 1-2 weeks

---

## Appendix: File-by-File Notes

### `llm_api_server/__init__.py`

**Purpose:** Public API exports

**Exports:**
- `LLMServer`
- `ServerConfig`
- `BUILTIN_TOOLS`
- `get_current_datetime`
- `calculate`
- `create_web_search_tool`
- `create_doc_search_tool`

**Notes:** Clean, minimal exports. Good practice.

---

### `llm_api_server/server.py`

**Key Classes:** `LLMServer`

**Critical Methods:**
| Method | Lines | Purpose |
|--------|-------|---------|
| `__init__` | 24-122 | Setup Flask, logging, rate limiting |
| `get_system_prompt` | 130-151 | Load prompt with caching |
| `execute_tool` | 153-198 | Run tool by name |
| `call_backend` | 200-210 | Dispatch to Ollama/LM Studio |
| `process_chat_completion` | 281-418 | Main request handler |
| `stream_chat_response` | 511-565 | Streaming handler |
| `chat_completions` | 590-642 | Route handler |
| `run` | 644-710 | Start server |

**Dependencies:** Flask, flask-cors, requests, langchain-core

---

### `llm_api_server/config.py`

**Key Classes:** `ServerConfig`

**Pattern:** Class attributes as defaults, `from_env()` classmethod for loading

**All Options:**
```python
# Backend
BACKEND_TYPE: Literal["lmstudio", "ollama"] = "lmstudio"
BACKEND_MODEL: str = "openai/gpt-oss-20b"
LMSTUDIO_ENDPOINT: str = "http://localhost:1234/v1"
OLLAMA_ENDPOINT: str = "http://localhost:11434"
OLLAMA_API_KEY: str = ""

# Server
DEFAULT_HOST: str = "127.0.0.1"
DEFAULT_PORT: int = 8000
DEFAULT_TEMPERATURE: float = 0.0
SYSTEM_PROMPT_PATH: str = "system_prompt.md"
THREADED: bool = True
MAX_TOOL_ITERATIONS: int = 5
MODEL_NAME: str = "llm-server/default"

# WebUI
WEBUI_PORT: int = 8001
ENABLE_WEBUI: bool = True

# Debug
DEBUG_TOOLS: bool = False
DEBUG_TOOLS_LOG_FILE: str = "tools_debug.log"
DEBUG_LOG_MAX_BYTES: int = 10 * 1024 * 1024
DEBUG_LOG_BACKUP_COUNT: int = 5

# Timeouts
BACKEND_CONNECT_TIMEOUT: int = 10
BACKEND_READ_TIMEOUT: int = 300

# Health
HEALTH_CHECK_ON_STARTUP: bool = True
HEALTH_CHECK_TIMEOUT: int = 5

# Retry
BACKEND_RETRY_ATTEMPTS: int = 3
BACKEND_RETRY_INITIAL_DELAY: float = 1.0

# Rate Limiting
RATE_LIMIT_ENABLED: bool = False
RATE_LIMIT_DEFAULT: str = "100 per minute"
RATE_LIMIT_STORAGE_URI: str = "memory://"

# Prompt Suggestions
DEFAULT_PROMPT_SUGGESTIONS: list | None = None
```

---

### `llm_api_server/backends.py`

**Key Functions:**
| Function | Purpose |
|----------|---------|
| `get_tool_schema(tool)` | Extract Pydantic schema from LangChain tool |
| `_retry_on_connection_error(func, config, *args, **kwargs)` | Retry wrapper |
| `call_ollama(messages, tools, config, temperature, stream)` | Ollama API call |
| `call_lmstudio(messages, tools, config, temperature, stream)` | LM Studio API call |
| `check_ollama_health(config, timeout)` | Health check |
| `check_lmstudio_health(config, timeout)` | Health check |

**API Formats:**
- Ollama: `POST /api/chat` with `model`, `messages`, `tools`, `stream`, `options`
- LM Studio: `POST /chat/completions` with OpenAI-compatible payload

---

### `llm_api_server/builtin_tools.py`

**Tools:**
| Name | Args | Returns |
|------|------|---------|
| `get_current_datetime` | None | `"Wednesday, November 26, 2025 at 2:30 PM PST"` |
| `calculate` | `expression: str` | Result or error string |
| `web_search` (factory) | `query, max_results, site` | Formatted search results |
| `doc_search` (factory) | `query, top_k` | Formatted document results |

**Pydantic Schemas:**
- `WebSearchInput` - query, max_results, site
- `DocSearchInput` - query, top_k

---

### `llm_api_server/rag/config.py`

**Key Class:** `RAGConfig` (dataclass)

**All Options:**
```python
# Core
base_url: str                           # Required
cache_dir: str | Path = "./rag_cache"
manual_urls: list[str] | None = None
manual_urls_only: bool = False

# Crawling
max_crawl_depth: int = 3
rate_limit_delay: float = 0.1
max_workers: int = 5
max_pages: int | None = None
request_timeout: float = 10.0
max_url_retries: int = 3
url_include_patterns: list[str] = []
url_exclude_patterns: list[str] = []

# Chunking
child_chunk_size: int = 350
child_chunk_overlap: int = 50
parent_chunk_size: int = 900
parent_chunk_overlap: int = 100

# Search
hybrid_bm25_weight: float = 0.3
hybrid_semantic_weight: float = 0.7
search_top_k: int = 5
retriever_candidate_multiplier: int = 3
rerank_enabled: bool = True

# Models
embedding_model: str = "all-MiniLM-L6-v2"
rerank_model: str = "cross-encoder/ms-marco-MiniLM-L-12-v2"

# Index
update_check_interval_hours: int = 168  # 7 days
```

---

### `llm_api_server/rag/crawler.py`

**Key Class:** `DocumentCrawler`

**Methods:**
| Method | Purpose |
|--------|---------|
| `__init__` | Setup, load robots.txt |
| `discover_and_crawl()` | Main entry point |
| `_discover_sitemap()` | Find and parse sitemap.xml |
| `_parse_sitemap_xml(xml_content)` | Parse sitemap/sitemap index |
| `_recursive_crawl()` | Follow links from base URL |
| `fetch_page(url)` | Fetch single page |
| `_normalize_url(url)` | Canonicalize URL |
| `_should_crawl_url(url)` | Apply include/exclude patterns |

---

### `llm_api_server/rag/chunker.py`

**Key Functions:**
| Function | Purpose |
|----------|---------|
| `count_tokens(text)` | Token count using tiktoken |
| `semantic_chunk_html(html, url, ...)` | Main chunking entry point |
| `_finalize_section(...)` | Create parent + children from section |
| `_split_large_section(...)` | Handle oversized sections |
| `_flush_parent_chunk(...)` | Create parent with children |
| `_split_oversized_part(...)` | Split on sentence boundaries |
| `_create_children_from_section(...)` | Create child chunks |
| `_generate_chunk_id(...)` | Stable chunk ID generation |
| `_build_metadata(...)` | Extract metadata from content |

**Constants:**
- `BOILERPLATE_SELECTORS` - CSS selectors for content to skip
- `MIN_CONTENT_LENGTH = 20` - Minimum chars for content block

---

### `llm_api_server/rag/indexer.py`

**Key Class:** `DocSearchIndex`

**Class Attributes:**
- `INDEX_VERSION = "1.0.0-parent-child"` - Cache invalidation version

**Instance Attributes:**
- `config` - RAGConfig
- `cache_dir`, `content_dir`, `index_dir` - Path objects
- `embeddings` - HuggingFaceEmbeddings (lazy)
- `vectorstore` - FAISS (lazy)
- `bm25_retriever` - BM25Retriever (lazy)
- `ensemble_retriever` - EnsembleRetriever (lazy)
- `cross_encoder` - CrossEncoder (lazy)
- `chunks` - list[Document]
- `parent_chunks` - dict[str, dict]
- `child_to_parent` - dict[str, str]
- `crawler` - DocumentCrawler

**Key Methods:**
| Method | Purpose |
|--------|---------|
| `needs_update()` | Check if rebuild needed |
| `crawl_and_index(force_rebuild)` | Main indexing pipeline |
| `load_index()` | Load from cache |
| `search(query, top_k, return_parent)` | Hybrid search with re-ranking |
| `_fetch_pages(...)` | Parallel page fetching |
| `_create_chunks(pages)` | Chunking pipeline |
| `_build_index()` | Build FAISS + BM25 |
| `_build_retrievers()` | Setup ensemble retriever |
| `_update_index_incremental()` | Add to existing index |
| `_rerank_results(query, results)` | Cross-encoder re-ranking |

---

### `llm_api_server/eval/evaluator.py`

**Key Class:** `Evaluator`

**Methods:**
| Method | Purpose |
|--------|---------|
| `check_health()` | Verify API is running |
| `send_question(question, timeout)` | Send single question |
| `run_test(test_case)` | Run single test |
| `run_tests(test_cases, stop_on_failure)` | Run test suite |
| `get_summary(results)` | Generate statistics |

---

### `llm_api_server/eval/validators.py`

**Key Function:** `validate_response(test_case, response)`

**Validation Checks:**
1. Minimum response length
2. Maximum response length (if set)
3. Expected keywords (case-insensitive)
4. Unexpected keywords (case-insensitive)
5. Custom validator function (if provided)

---

### `tests/conftest.py`

**Fixtures:**
| Fixture | Returns |
|---------|---------|
| `default_config` | `ServerConfig()` |
| `custom_config` | Modified ServerConfig |
| `sample_messages` | Chat message list |
| `sample_tools` | List with test echo tool |

---

### `tests/test_server.py`

**Test Classes:**
| Class | Tests |
|-------|-------|
| `TestLLMServer` | Initialization, tool execution, system prompt |
| `TestServerRoutes` | `/health`, `/v1/models`, `/v1/chat/completions` validation |

---

## Conclusion

This codebase demonstrates solid engineering practices with clean architecture, good documentation, and thoughtful error handling. The main areas requiring attention are:

1. **Security hardening** - Calculator validation, FAISS integrity
2. **Cache reliability** - Parent context after restart
3. **Test coverage** - RAG module needs tests
4. **Performance** - Connection pooling, token budgets

The RAG module is particularly impressive in its sophistication while remaining readable. With the recommended fixes, this would be a production-ready framework.

---

*Review completed: 2025-11-27*
*Reviewer: Claude (Opus 4.5)*
*Total files reviewed: 26*
*Total lines analyzed: ~6,355*
